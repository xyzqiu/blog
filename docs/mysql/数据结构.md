
# 1、 二叉排序树
![[截屏2023-10-03 14.41.41.png]]

## 1、性质
- 若它的左子树不为空，则左子树上所有节点的值均小于它根节点的值
- 若它的右子树不为空，则右子树上所有节点的值均大于它根节点的值
二叉排序树与二叉树一样，也是通过递归的形式定义的。因此，它的操作也都是基于递归的方式。

中序遍历：左根右；先左子树，没左子树就根，然后遍历右子树。

构建二叉排序树的过程就是插入 过程：
```c
void insert(int key)
{
	//定义一个临时指针 用于移动
	Node* temp = root;//方便移动 以及 跳出循环
	Node* prev = NULL;//定位到待插入位置的前一个结点
	while (temp != NULL)
	{
		prev = temp;
		if (key < temp->data)
		{
			temp = temp->left;
		}
		else if(key > temp->data)
		{
			temp = temp->right;
		}
		else
		{
			return;
		}
	}
 
	if (key < prev->data)
	{
		prev->left = (Node*)malloc(sizeof(Node));
		prev->left->data = key;
		prev->left->left = NULL;
		prev->left->right = NULL;
	}
	else
	{
		prev->right = (Node*)malloc(sizeof(Node));
		prev->right->data = key;
		prev->right->left = NULL;
		prev->right->right = NULL;
	}
}

```

## 2、查找操作
其查找操作与二分查找非常相似。它的操作并不是把中序遍历的结果存入数组，然后在有序数组里查找，而是直接在树上查找。
1. 首先，访问根节点8
2. 根据性质，7比8小，所以如果7存在，那应该在8的左子树那边，访问8的左子树
3. 访问到了3，根据第2步的思想，访问3的右子树
4. 访问到了6，继续访问6的右子树
5. 访问到了7，刚好找到啦！
![[截屏2023-10-03 15.06.54.png]]

代码：
```C
/*查找元素Key*/
bool search(Node* root, int key){
	while(root != Null){
		if(key == root->data)
			return true;
		else if(key < root->data)
			root = root->left;
		else 
			root = root->right;
	}
	return false;
}
```

## 3、删除操作

### 3.1、被删除节点为叶子节点
直接从二叉排序树中删除即可，不会影响到其他节点。例如删去7:

![[截屏2023-10-03 15.11.54.png]]

### 3.2、被删除节点D仅有一个孩子
- 如果只有左孩子，没有右孩子，那么只需要把要删除节点的左孩子连接到要删除节点的父亲节点，然后删除D节点
- 如果只有右孩子，那么只需要把删除节点的右孩子连接到要删除节点的父亲节点，然后删除节点。

以删除节点14为例：
![[截屏2023-10-03 15.15.13.png]]
### 3.3、被删除节点的左右孩子都在
假设删除根节点8。
我们的目标依然是要保证删除节点8后，再次中序遍历它，仍不改变其升序的排列方式。那么我们只有**用7或者10来替代8**原来的位置

![[截屏2023-10-03 15.19.29.png]]![[截屏2023-10-03 15.19.58.png]]
**为什么是7或者10来替换8的位置**？
显然，7与10是挨着8的，如果用其他元素替换则会打扰其顺序。
**那7和10怎么在二叉排序树中找到呢**？
显然，==7在8左子树的“最右边”，10在8右子树的“最左边”==。根据二叉排序树的插入方式，比8小的元素一定在左子树，而我们又要找到比8小的最大的数，这样才能保证他们俩在顺序上是挨着的，所以它又会在8的左子树的最右边。同理也可以找到10。

完整代码：
```c
#include<stdio.h>
#include<stdlib.h>
typedef struct SortTree {
	int data;//存放数据的数据域
	struct SortTree* left;//指针域 左指针
	struct SortTree* right;//指针域 右指针
}Node;
/*全局变量*/
Node* root;//根节点
 
void Init(int);//初始化操作
void insert(int);//插入操作
void show(Node*);
int delete_node(Node*, int);
Node* prev_node(Node*, Node*, int);
bool search(Node* root, int key);
int main()
{
	Init(8);
	insert(4);
	insert(2);
	insert(5);
	insert(10);
	insert(9);
	insert(13);
	show(root);
	delete_node(root, 8);
	delete_node(root, 13);
	printf("\n");
	show(root);
}
 
/*初始化根节点
int key : 根节点的值
*/
void Init(int key)
{
	root = (Node*)malloc(sizeof(Node));
	root->data = key;
	root->left = NULL;
	root->right = NULL;
}
 
void insert(int key)
{
	//定义一个临时指针 用于移动
	Node* temp = root;//方便移动 以及 跳出循环
	Node* prev = NULL;//定位到待插入位置的前一个结点
	while (temp != NULL)
	{
		prev = temp;
		if (key < temp->data)
		{
			temp = temp->left;
		}
		else if(key > temp->data)
		{
			temp = temp->right;
		}
		else
		{
			return;
		}
	}
 
	if (key < prev->data)
	{
		prev->left = (Node*)malloc(sizeof(Node));
		prev->left->data = key;
		prev->left->left = NULL;
		prev->left->right = NULL;
	}
	else
	{
		prev->right = (Node*)malloc(sizeof(Node));
		prev->right->data = key;
		prev->right->left = NULL;
		prev->right->right = NULL;
	}
}
 
void show(Node* root)
{
	if (root == NULL)
	{
		return;
	}
	show(root->left);
	printf("%d ", root->data);
	show(root->right);
}
/*查找元素key*/
bool search(Node* root, int key)
{
	while (root != NULL)
	{
		if (key == root->data)
			return true;
		else if (key < root->data)
			root = root->left;
		else
			root = root->right;
	}
	return false;
}
int delete_node(Node* node, int key)
{
	if (node == NULL)
	{
		return -1;
	}
	else
	{
		if (node->data == key)
		{
			//当我执行删除操作 需要先定位到前一个结点
			Node* tempNode = prev_node(root, node, key);
			Node* temp = NULL;
			/*
			如果右子树为空 只需要重新连接结点
			叶子的情况也包含进去了 直接删除
			*/
			if (node->right == NULL)
			{
				temp = node;
				node = node->left;
				/*为了判断 待删除结点是前一个结点的左边还是右边*/
				if (tempNode->left->data == temp->data)
				{
					Node* free_node = temp;//释放用的指针
					tempNode->left = node;
					free(free_node);
					free_node = NULL;
				}
				else
				{
					Node* free_node = temp;//释放用的指针
					tempNode->right = node;
					free(free_node);
					free_node = NULL;
				}
			}
			else if (node->left == NULL)
			{
				temp = node;
				node = node->right;
				if (tempNode->left->data == temp->data)
				{
					Node* free_node = temp;//释放用的指针
					tempNode->left = node;
					free(free_node);
					free_node = NULL;
				}
				else
				{
					Node* free_node = temp;//释放用的指针
					tempNode->right = node;
					free(free_node);
					free_node = NULL;
				}
			}
			else//左右子树都不为空
			{
				temp = node;
				/*往左子树 找最大值*/
				Node* left_max = node;//找最大值的临时指针
				left_max = left_max->left;//先到左孩子结点
				while (left_max->right != NULL) 
				{
					temp = left_max;
					left_max = left_max->right;
				}
				node->data = left_max->data;
				if (temp != node)
				{
					temp->right = left_max->left;
					free(left_max);
					left_max = NULL;
				}
				else
				{
					temp->left = left_max->left;
					free(left_max);
					left_max = NULL;
				}
			}
			
		}
		else if(key < node->data)
		{
			delete_node(node->left, key);
		}
		else if (key > node->data)
		{
			delete_node(node->right, key);
		}
	}
}
/*定位到待删除节点的前一个结点
Node* root 从根节点开始
Node* node 待删除的结点
int key 待删除数据
*/
Node* prev_node(Node* root, Node* node, int key)
{
	if (root == NULL || node == root)
	{
		return node;
	}
	else
	{
		if (root->left != NULL && root->left->data == key)
		{
			return root;
		}
		else if(root->right != NULL && root->right->data == key)
		{
			return root;
		}
		else if (key < root->data)
		{
			return prev_node(root->left, node, key);
		}
		else
		{
			return prev_node(root->right, node, key);
		}
	}
}

```


二叉排序树用于查找，存在斜树问题，也会导致查找效率低：
![[截屏2023-10-03 15.43.26.png]]



# 2、平衡二叉树 AVL
![[截屏2023-10-03 15.44.43.png]]

平衡二叉树判断标准
- 是二叉排序树
- 任何一个节点的左子树或者右子树都是**平衡二叉树**（左右高度差小于等于1）

## 2.1、相关概念
### 2.1.1、平衡因子
定义：左子树和右子树高度差
计算：左子树高度 - 右子树高度的值
别名：简称BF（Balance Factor）
> 一般来说BF的绝对值大于1，平衡二叉树就失衡，需要「旋转」纠正。

### 2.1.2、最小不平衡子树
距离插入节点最近的，并且BF的绝对值大于1的节点为根节点的子树。
![[截屏2023-10-03 15.55.53.png]]

### 2.1.3、两种旋转方式

1. 左旋
- 旧根节点为新根节点的左子树
- 新根节点的左子树（如果存在）为旧根节点的右子树

1. 右旋
- 旧根节点为新根节点的右子树
- 新根节点的右子树（如果存在）为旧根节点的左子树

4中「旋转」纠正类型：
1. LL型：插入左孩子的左子树，右旋
2. RR 型：插入右孩子的右子树，左旋
3. LR 型：插入左孩子的右子树，先左旋，再右旋
4. RL 型：插入右孩子的左子树，先右旋，再左旋

![[截屏2023-10-03 16.03.43.png]]
**1、LL型失衡「右旋」**
- 旧根节点（节点 3）为新根节点（节点 2）的右子树
- 新根节点的 **右子树**（如果存在）为旧根节点的左子树
![](https://img-blog.csdnimg.cn/img_convert/bc202c8af7a2fe17150674ebf9d2c80a.gif)

 **2、RR 型失衡「左旋」**

第三个节点「3」插入的 时候，`BF(1)=-2 BF(2)=-1`，**RR 型失衡**，左旋，根节点逆时针旋转

（1）最小不平衡子树左旋

> 左旋
> 
> - 旧根节点（节点 1）为新根节点（节点 2）的左子树
> - 新根节点的左子树（如果存在）为旧根节点的右子树

![](https://img-blog.csdnimg.cn/img_convert/bc202c8af7a2fe17150674ebf9d2c80a.gif)
 **3、 LR 型**
第三个节点「3」插入的 时候，BF(3)=2 BF(1)=-1 LR 型失衡，先「左旋」再「右旋」

（1）最小不平衡子树左子树 {2,1} 先左旋

左旋
旧根节点（节点 1）为新根节点（节点 2）的左子树
新根节点的左子树（如果存在）为旧根节点的右子树
![[3.gif]]
2）最小不平衡子树 `{3,2,1}` 再右旋

> 右旋

- 旧根节点（节点 3）为新根节点（节点 2）的右子树
- 新根节点的 **右子树**（如果存在）为旧根节点的左子树
![[4.gif]]
**4、RL型**
第三个节点「1」插入的 时候，`BF(1)=-2 BF(3)=1` **RL 型失衡**，先「右旋」再「左旋」

（1）最小不平衡子树根节点右子树`{3,2}`先右旋

> 右旋
> 
> - 旧根节点（节点 3）为新根节点（节点 2）的右子树
> - 新根节点的 **右子树**（如果存在）为旧根节点的左子树

![[5.gif]]
（2）最小不平衡子树 `{1,2,3}` 再左旋（L）

> 左旋

- 旧根节点（节点 1）为新根节点（节点 2）的左子树
- 新根节点的左子树（如果存在）为旧根节点的右子树
![[6.gif]]
# 3、红黑树
[原文地址](https://blog.csdn.net/cy973071263/article/details/122543826?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522169631363516800182156012%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=169631363516800182156012&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-122543826-null-null.142^v94^chatsearchT3_1&utm_term=红黑树&spm=1018.2226.3001.4187)
## 3.1、简介
红黑树是一种自平衡的二叉查找树，是一种高效的查找树。红黑树具有良好的效率，它可在O(logN)时间内完成查找、增加、删除等操作。
**为什么需要红黑树？**
对于二叉搜索树，如果插入的数据是随机的，那么它就是接近平衡的二叉树，平衡的二叉树，它的操作效率（查询，插入，删除）效率较高，时间复杂度是O(logN)。但是可能会出现一种极端的情况，那就是插入的数据是有序的（递增或递减），那么所有的节点都会在根节点的左侧或者右侧。此时，二叉搜索树就变成了一个链表，它的操作效率就降低了，时间复杂度为O(N)，所以可以认为二叉搜索树的时间复杂度介于O(logN)和O(N)之间，视情况而定。为了应对这种极端情况，红黑树就出现了，==它是具备了某些特性的二叉搜索树，能解决非平衡树的问题，红黑树是一种接近平衡的二叉树（说他是接近平衡因为它并没有像AVL树的平衡因子的概念，它知识靠着满足红黑树节点的5条性子来维持一种接近平衡的结构，进而提升整体的性能，并没有严格的卡定某个平衡因子来维持绝对平衡）。==

## 3.2、特性
在讲解红黑树性质之前，先简单了解一下几个概念：

- parent：父节点
- sibling：兄弟节点
- uncle：叔父节点（ parent 的兄弟节点）
- grand：祖父节点（ parent 的父节点）
首先，红黑树是一个二叉搜索树，他在每个节点增加了一个存储记录节点的颜色，可以是RED，也可以是BLACK；通过任意一条从根到叶子简单路径上的颜色的约束，==红黑树保证最长路径不超过最短路径的二倍，因而近似平衡（最短路径就是全黑节点，最长路径就是一个红节点一个黑节点，当从根节点到叶子节点的路径上黑色节点相同时，最长路径刚好是最短路径的两倍）。==它同时满足以下特性：


1. 节点是<font color = "red">红色</font>或**黑色** 
2. 根是**黑色**
3. 1. 叶子节点（外部节点，空节点）都是**黑色**，这里的叶子节点指的是最底层的空节点（外部节点），下图中的那些null节点才是叶子节点，null节点的父节点在红黑树里不将其看作叶子节点
4. <font color = "red">红色</font>节点的子节点都是**黑色**
	1. <font color = "red">红色</font>节点的父节点都是黑色
	2. 从根节点到叶子节点的所有路径上不能有2个连续的<font color = "red">红色</font>节点
5. 从任一节点到子节点的所有路径都包含相同的**黑色**节点。
![[截屏2023-10-03 17.08.48.png]]


## 3.3、红黑树的效率
==红黑树的查找，查询和删除操作，时间复杂度都是O(logN)。==
**查找操作时**，它和普通的相对平衡的二叉搜索树的效率是相通的，都是通过相同的方式来查找的，没有用到红黑树特有的特性。
但如果**插入的时候**时有序数据，那么红黑树的查询效率就比二叉搜索树要高了，因为此时二叉搜索树不是平衡树，它的时间复杂度O(N)。
**插入和删除操作**时，由于红黑树的每次操作平均要旋转一次和变换颜色，所以它比普通的二叉搜索树效率要低一点，不过时间复杂度仍然是O(logN)。总之，==红黑树的优点就是对有序数据的查询操作不会慢到O(logN)的时间复杂度。==

## 3.4、红黑树和AVL树的比较
1. AVL树的时间复杂度虽然优于红黑树，但是对于现在的计算机，cpu太快，可以忽略性能差异
2. 红黑树的**插入删除**比AVL树更便于控制操作
3. 红黑树整体性能略优于AVL树（红黑树旋转情况少于AVL树）

## 3.5、红黑树的等价变换
![[截屏2023-10-03 17.17.14.png]]
由上面的等价变换我们就可以得到如下结论：

红黑树 和 4阶B树（2-3-4树）具有等价性
黑色节点与它的红色子节点融合在一起，形成1个B树节点
红黑树的黑色节点个数 与 4阶B树的节点总个数相等
在所有的B树节点中，永远是黑色节点是父节点，红色节点是子节点。黑色节点在中间，红色节点在两边。

![[截屏2023-10-03 17.21.17.png]]
## 3.6、红黑树的操作
红黑树的基本操作和其他树形结构一样，一般都包括查找、插入、删除等操作。==前面说到，红黑树是一种自平衡的二叉查找树，既然时二叉查找树的一种，那么查找过程和二叉查找树一样，比较简单，==这里不再赘述。==相对于查找操作，红黑树的插入和删除操作就要复杂的多。尤其是删除操作，要处理的情况比较多，==下面就分情况讲解。

### 3.6.1、旋转操作
红黑树在经过插入和删除后，结构会发生变化，不再满足红黑树的性质。旋转操作用于维护红黑性质，就像平衡二叉树（AVL）旋转用于维护平衡性。旋转后红黑树需满足二叉搜索树的性质，即一个节点的值大于其左子树所有节点的值，其右子树所有节点的值大于这个节点的值。

在分析插入和删除操作前，先说明一些旋转操作，这个操作在后续操作中都会用得到。旋转操作分为左旋和右旋，==「左旋」是将某个节点旋转为其右孩子的左孩子，而「右旋」是节点旋转为其左孩子的右孩子。==
![[截屏2023-10-03 17.41.24.png]]
上图包含了左旋和右旋的示意图，这里以右旋为例进行说明，右旋节点 M 的步骤如下：

1. 将节点 M 的左孩子引用指向节点 E 的右孩子
2. 将节点 E 的右孩子引用指向节点 M，完成旋转

![[截屏2023-10-03 17.43.59.png]]
**右旋某个节点**：将该节点的左孩子作为根节点，新树的左孩子为原结构左孩子的左孩子（如果存在），新树的右孩子为进行右旋的节点，新树右孩子的左孩子为原结构左孩子的右孩子。
**左旋某个节点**：将该节点的右孩子作为根节点，新树的左孩子为原结构的根节点，新树的左孩子的右孩子为原结构中右孩子的左孩子，新树的右孩子为原结构右孩子的右孩子（如果存在）。

### 3.6.2、插入操作
==红黑树的插入过程和二叉查找树插入过程基本类似，不同的地方在于，红黑树插入新节点后，需要进行调整，以满足红黑树的性质。==

==性质1规定红黑树节点的颜色要么是红色要么是黑色，那么在插入新节点时，这个节点应该是红色还是黑色呢？答案是<font color = "red">红色</font>==，原因也不难理解。如果插入的节点是黑色，那么这个节点所在路径比其他路径多出一个黑色节点，这个调整起来会比较麻烦（参考红黑树的删除操作，就知道为啥多一个或少一个黑色节点时，调整起来这么麻烦了）。如果插入的节点是红色，此时所有路径上的黑色节点数量不变，仅可能会出现两个连续的红色节点的情况。这种情况下，通过变色和旋转进行调整即可，比之前的简单多了。==所以插入的时候将节点设置为红色，可以保证满足性质 1、2、3、5 ，只有性质4不一定满足，需要进行相关调整。如果是添加根节点，则将节点设定为黑色。

#### 3.6.2.1、插入操作的所有情况
我们在分析红黑树各种插入情况的时候，将其等价转换为B树，这样我们能够更直观的进行分类，首先确定几条性质：

- B树中，新元素必定是添加到叶子节点中（最底层的节点）
- 4阶B树所有节点的元素个数 x 都符合 1 ≤ x ≤ 3

![[截屏2023-10-03 19.02.29.png]]

在上一章节红黑树的等价变换中，我们讲到了红黑树转换成B树总共有四种情况，也就是上图中叶子节点这四种情况，那么在我们进行插入操作的时候，会将节点插入到所有的叶子节点中，总共就会有12种情况，其中四种情况满足红黑树的性质，8种情况不满足红黑树性质。

##### 6.2.1.1.1、满足红黑树性质4
有 4 种情况满足红黑树的性质 4 ：**parent** **为黑色节点**。这四种情况不需要做任何额外的处理。
![[截屏2023-10-03 19.04.54.png]]
##### 6.2.1.1.2、不满足红黑树性质4
有 8 种情况不满足红黑树的性质 4 ：parent 为红色节点（ Double Red ），其中左面4种属于B树节点上溢的情况（一个4阶B树节点中最多存放三个数，这四种情况本来已经有3个了，又插入了1个，变成了4个，超出了4阶B树节点的容量范围，这种情况称为上溢）。这八种情况需要进行额外的处理。
![[截屏2023-10-03 19.06.49.png]]

#### 3.6.2.2、LL和RR插入情况
![[截屏2023-10-03 19.08.22.png]]

如上图，插入52和60的位置分别是RR情况和LL情况。

RR情况：父节点为祖父节点的右节点，插入节点为父节点的右节点

LL情况：父节点为祖父节点的左节点，插入节点为父节点的左节点

这两种情况很明显，插入节点为红色，父节点也为红色，父节点的子节点为红色显然违背了红黑树的性质四，我们需要对这种情况进行修复，使其重新满足红黑树性质。
判定条件：uncle 不是红色节点。

这里的两种情况，他们的插入节点都是没有叔父节点的，所以叔父节点也不可能是红色。

案例修复：

我们在红黑树等价转换那一章节也讲过了，红黑树等价转换成B树之后，B树节点的中间节点（父节点）都是黑色，两边的节点（子节点）都是红色。但是上面两种情况插入后，插入位置的B树节点并不满足这个条件，所以我们对其进行修复，使其满足B树节点的条件之后，也就重新恢复了红黑树性质。

B树节点中的中间节点大小介于两个子节点之间。以上图RR情况为例，插入节点52的原父节点应该放在B树节点中间的位置，应当将其染成黑色。插入节点52的原祖父节点46，应当将其转换为插入节点原父节点的子节点，所以将其染成红色。LL情况同理

完成染色之后，需要对原祖父节点进行单旋操作，来进行父节点，子节点的重新分配。以上图为例：

RR情况应该原祖父节点46左旋，将插入节点的原父节点50旋转到中间的位置。
LL情况应当原祖父节点76右旋，将插入节点的原父节点72旋转到中间的位置。
修复之后的结果如下图：
![[截屏2023-10-03 19.13.57.png]]
**修复步骤总结：**

1. parent 染成黑色，grand 染成红色
2. grand 进行单旋操作 
    1. LL：右旋转
    2. RR：左旋转

#### 3.6.2.3、LR和RL插入情况
平衡二叉树的旋转和红黑树旋转的前提：1）平衡二叉树插入后不满足平衡的条件（即左子树高度 - 右子树高度 的绝对值 > 1,BF 平衡因子> 1）需要进行旋转。2）红黑树插入或删除后，不满足红黑树的性质需要进行旋转。

如上图，插入48和74的位置分别是RL情况和LR情况。

RL情况：父节点为祖父节点的右节点，插入节点为父节点的左节点

LR情况：父节点为祖父节点的左节点，插入节点为父节点的右节点

这两种情况和上面的两种情况一样，插入节点为红色，父节点也为红色，父节点的子节点为红色显然违背了红黑树的性质四，我们需要对这种情况进行修复，使其重新满足红黑树性质。

判定条件：uncle 不是红色节点。

这两种情况的插入节点也是没有叔父节点的。

案例修复：

B树节点中的中间节点大小介于两个子节点之间。以上图RL情况为例，插入节点48大小介于原父节点和原祖父节点之间，它应该是B树节点中的中间节点，所以将插入节点48染成黑色，将原祖父节点46染成红色来作为插入节点的子节点。LR情况同理

完成染色之后，需要进行双旋操作，来进行父节点，子节点的重新分配。以上图为例：

RL情况应该原父节点50右旋，将插入节点48上移到原父节点50的高度，然后将插入节点的原祖父节点46进行左旋，将插入节点48移动到中间位置，成为中间节点。
LR情况应该原父节点72左旋，将插入节点74上移到原父节点72的高度，然后将插入节点的原祖父节点76进行右旋，将插入节点74移动到中间位置，成为中间节点。
修复之后的结果如下图：
![[截屏2023-10-03 19.21.39.png]]
**修复步骤总结：**

1. 插入节点染成黑色，grand 染成红色
2. 进行双旋操作 
    - LR：parent 左旋转， grand 右旋转
    - RL：parent 右旋转， grand 左旋转


# 4、B树、B+树、B * 树
[原文地址](http://t.csdnimg.cn/DWArz)

## 1、前言
动态查找树主要有：二叉查找树（Binary Search Tree），平衡二叉查找树（Balanced Binary Search Tree），红黑树（Red- Black Tree），B- Tree/B+-Tree/B*- Tree。前三者是典型的二叉查找树结构，其查找的时间复杂度O（log2N）与树的深度相关，那么降低树的深度自然会提高查找效率。

但是咱们又面对这样一个实际问题：就是大规模数据存储中，实现索引查询这样一个实际背景下，树节点存储的元素数量是有限的（如果元素数量非常多的话，查找就退化为节点内部的线性查找了），这样导致二叉查找树结构由于树的深度过大而造成磁盘I/O读写过于频繁，进而导致查询效率低下（为什么会出现这种情况，待会在外部存储器-磁盘中有所解释），那么如何减少树的深度（当然是不能减少查询的数据量），一个基本的想法就是：采用多叉树结构（由于树节点元素数量是有限的，自然该节点的子树数量也就是有限的）。

也就是说，因为磁盘的操作费时费资源，如果过于频繁的多次查找势必效率低下。那么如何提高效率，即如何避免磁盘过于频繁的多次查找呢？根据磁盘查找存取的次数往往由树的高度所决定，所以，只要我们通过某种较好的树结构减少树的结构尽量减少树的高度，那么是不是便能有效减少磁盘查找存取的次数呢？那这种有效的树结构是一种怎样的树呢？

这样我们就提出了一个新的查找树结构——多路查找树。根据平衡二叉树的启发，自然就想到平衡多路查找树结构，也就是这篇文章所要阐述的第一个主题B~tree，即B树结构(后面，我们将看到，B树的各种操作能使B树保持较低的高度，从而达到有效避免磁盘过于频繁的查找存取操作，从而有效提高查找效率)。

B-tree（B-tree树即B树，B即Balanced，平衡的意思）这棵神奇的树是在Rudolf Bayer, Edward M. McCreight(1970)写的一篇论文《Organization and Maintenance of Large Ordered Indices》中首次提出的（wikipedia中：http://en.wikipedia.org/wiki/B-tree，阐述了B-tree名字来源以及相关的开源地址）。

## 2、外存储器-磁盘
计算机存储设备一般分为两种：内存储器（main memory）和外存储器（external memory）。内存存取速度快，但容量小，价格昂贵，而且不能长期保存数据（在不通电情况下数据会消失）。

外存储器-磁盘是一种字节存取的存储设备（DASD）。它是以存取时间变化不大为特征的。可以直接存取任何字符组，且容量大、速度较其他外存设备更快。

### 2.1、磁盘的构造
磁盘是一个扁平的圆盘（与💿类似）。盘面上有许多称为磁道的圆圈，数据就记录在这些磁道上。磁盘可以是单片的，也可以是由若干盘片组成的盘组，每一个盘片上有两个面。如下图11.3中所示的6片盘组为例，除去最顶端和最底端的外侧面不存储数据之外，一共有10个面可以用来保存信息。

![[截屏2023-10-04 12.50.57.png]]


当磁盘驱动器执行读/写功能时。盘片装在一个主轴上，并绕主轴高速旋转，当磁道在读/写头(又叫磁头) 下通过时，就可以进行数据的读 / 写了。

一般磁盘分为固定头盘(磁头固定)和活动头盘。固定头盘的每一个磁道上都有独立的磁头，它是固定不动的，专门负责这一磁道上数据的读/写。

活动头盘 (如上图)的磁头是可移动的。每一个盘面上只有一个磁头(磁头是双向的，因此正反盘面都能读写)。它可以从该面的一个磁道移动到另一个磁道。所有磁头都装在同一个动臂上，因此不同盘面上的所有磁头都是同时移动的(行动整齐划一)。当盘片绕主轴旋转的时候，磁头与旋转的盘片形成一个圆柱体。各个盘面上半径相同的磁道组成了一个圆柱面，我们称为柱面 。因此，柱面的个数也就是盘面上的磁道数。 

### 2.2、磁盘的读/写原理和效率
磁盘上数据必须用一个三维地址唯一标示：柱面号、盘面号、块号(磁道上的盘块)。

读/写磁盘上某一指定数据需要下面3个步骤：

(1)  首先移动臂根据柱面号使磁头移动到所需要的柱面上，这一过程被称为定位或查找 。

(2)  如上图11.3中所示的6盘组示意图中，所有磁头都定位到了10个盘面的10条磁道上(磁头都是双向的)。这时根据盘面号来确定指定盘面上的磁道。

(3) 盘面确定以后，盘片开始旋转，将指定块号的磁道段移动至磁头下。

经过上面三个步骤，指定数据的存储位置就被找到。这时就可以开始读/写操作了。

访问某一具体信息，由3部分时间组成：

● 查找时间(seek time) Ts: 完成上述步骤(1)所需要的时间。这部分时间代价最高，最大可达到0.1s左右。

● 等待时间(latency time) Tl: 完成上述步骤(3)所需要的时间。由于盘片绕主轴旋转速度很快，一般为7200转/分(电脑硬盘的性能指标之一, 家用的普通硬盘的转速一般有5400rpm(笔记本)、7200rpm几种)。因此一般旋转一圈大约0.0083s。

● 传输时间(transmission time) Tt: 数据通过系统总线传送到内存的时间，一般传输一个字节(byte)大概0.02us=2 * 10^(-8)s

**磁盘读取数据是以盘块（block）为基本单位的**。位于同一盘块中的所有数据都能被一次性全部读取出来。而磁盘IO代价主要花费在查找时间Ts上。因此我们应该尽量将相关信息存放在同一盘块，同一磁道中。或者至少放在同一柱面或相邻柱面上，**以求在读写信息时尽量减少磁头来回移动的次数，避免过多的查找时间Ts**

所以，在大规模数据存储方面，大量数据存储在外存磁盘中，而在外存磁盘中读取/写入块(block)中某数据时，首先需要定位到磁盘中的某块，如何有效地查找磁盘中的数据，需要一种合理高效的外存数据结构，就是下面所要重点阐述的B-tree结构，以及相关的变种结构：B+-tree结构和B*-tree结构。

## 3.1、什么是B树
具体讲解之前，有一点，再次强调下：有的文章里出现的B-树，即为B树。因为B树的原英文名称为B-tree，而国内很多人喜欢把B-tree译作B-树，其实，这是个非常不好的直译，很容易让人产生误解。如人们可能会以为B-树是一种树，而B树又是一种一种树。而事实上是，B-tree就是指的B树。特此说明。

我们知道，B 树是为了磁盘或其它存储设备而设计的一种多叉（下面你会看到，相对于二叉，B树每个内结点有多个分支，即多叉）平衡查找树。与本blog之前介绍的红黑树很相似，但在降低磁盘I/0操作方面要更好一些。许多数据库系统都一般使用B树或者B树的各种变形结构，如下文即将要介绍的B+树，B * 树来存储信息。

如下图所示，即是一棵B树，一棵关键字为英语中辅音字母的B树，现在要从树种查找字母R（包含n[x]个关键字的内结点x，x有n[x]+1]个子女（也就是说，一个内结点x若含有n[x]个关键字，那么x将含有n[x]+1个子女）。所有的叶结点都处于相同的深度，带阴影的结点为查找字母R时要检查的结点）：
![[截屏2023-10-04 13.42.40.png]]
**相信，从上图你能轻易的看到，一个内结点x若含有n[x]个关键字，那么x将含有n[x]+1个子女。如含有2个关键字D H的内结点有3个子女，而含有3个关键字Q T X的内结点有4个子女。**

B树又叫==平衡多路查找树。==一颗m阶的B树的特性如下：（注：一棵m阶的B树不是m叉树）
 1. 每个节点至多有m棵子树。
 2. 除根节点外，其他每个分支节点至少有[ m / 2]棵子树。
 3. 根节点至少有两棵子树（除非B树只包含一个节点）。
 4. 所有叶子节点在同一层上。
 5. 有j个孩子的非叶子节点恰好有j-1个关键码，关键码按递增次序排序。

 


















# 5、哈希散列
# 6、数组、链表
